---
layout: post
title: "Superchare R with Spark: Apache's SparkR"
category: Machine Learning
tags: modeling r
year: 2015
month: 09
day: 30
published: true
summary: "See how easy it is to set up a few SparkR clusters and control them from RStudio. In this first installment, we'll set up multiple clusters on AWS EC2 and control them via RStudio."
image: SparkR/Spark.png
---
**Resources**
<ul>
<li type="square"><a href="https://www.youtube.com/watch?v=3HuYr6G2Z28&list=UUq4pm1i_VZqxKVVOz5qRBIA&index=1" target='_blank'>YouTube Companion Video</a></li>

</ul>
<BR>
<a href='http://spark.apache.org/' target='_blank'>Spark</a> doesn’t need an introduction, but just in case, it extends Hadoop’s distributed/parallel computing paradigm by distributing tasks using both live memory and disk storage. As of version 1.4, SparkR is included in Apache's Spark build. We'll be using version 1.5 here.

This will be a two-part series, here we'll install <b>SparkR</b> on <b>EC2</b> and fire up a few clusters. In the second part, will do some distributed modeling.

***Let's get right to it***

In order to approach this from the same vantage point, we’ll use a small EC2 instance to launch our Spark clusters. You will need an amazon aws account and the ability to SSH into AWS (more on this later). 

First, sign into the <a href='http://aws.amazon.com/' target="_blank">AWS Console</a>

<p style="text-align:center">
<img src="../img/posts/SparkR/AWS.png" alt="logging_on_AWS" style='padding:1px; border:1px solid #021a40;'></p>

**Under header Networking, select VPC**

<p style="text-align:center">
<img src="../img/posts/SparkR/vpc.png" alt="VPC" style='padding:1px; border:1px solid #021a40;'></p>

A <b>virtual private cloud (VPC)</b> will determine who and what gets to access the site. We will use the wizard and content ourselves with only on VPC. In an enterprise-level application, you will want at least 4, 2 to be private and run your database, and two to be public and hold your web-serving application. By duplicating the private and public VPCs you can benefit from fail-over and load balancing tools. By keeping things simple, we’ll get our instance working in just a few clicks, seriously!

Start the ``wizard`` 

<p style="text-align:center">
<img src="../img/posts/SparkR/vpc_wizard.png" alt="VPC Wizard" style='padding:1px; border:1px solid #021a40;'></p>

Start the wizard and select ``VPC with a Single Public Subnet``: 

<p style="text-align:center">
<img src="../img/posts/SparkR/vpc_configuration.png" alt="VPC Configuration" style='padding:1px; border:1px solid #021a40;'></p>

Most of the defaults are fine except you should add a name under ``VPC name``: 

<img src="../img/posts/SparkR/vpc_single_subnet.png" alt="Single Subnet" style='padding:1px; border:1px solid #021a40;'></p>

***EC2***

VPC is done, let’s now create our EC2 instance - this is going to be our cluster-launching machine. Click on the orange cube in the upper left corner of the page. From the ensuing menu, choose the first option, ``EC2``:

<img src="../img/posts/SparkR/ec2.png" alt="EC2 Icon" style='padding:1px; border:1px solid #021a40;'></p>

In ``Create Instance``, select ``Launch Instance``: 


<img src="../img/posts/SparkR/create_instance.png" alt="Create Instance" style='padding:1px; border:1px solid #021a40;'></p>

Select the first option ``Amazon Linux AMI``:

<img src="../img/posts/SparkR/amazon_ami.png" alt="Create Instance" style='padding:1px; border:1px solid #021a40;'></p>

In **Step 2**, continue with the preselected machine and click ``Next: Configure Instance Details``:

e<img src="../img/posts/SparkR/ec2_step2.png" alt="Create Instance" style='padding:1px; border:1px solid #021a40;'></p>

In **Step 3**, keep all defaults but change the ``Auto-assign Public IP`` to ``Enable``:

<img src="../img/posts/SparkR/step_3.png" alt="IP" style='padding:1px; border:1px solid #021a40;'></p>

Select ``Review and Launch``:


<img src="../img/posts/SparkR/review_launch.png" alt="Review Launch" style='padding:1px; border:1px solid #021a40;'></p>

In **Step 7**, ``SSH port 22`` is opened by default so there is nothing for us to do but to click ``Launch``.

It will open a pop-up box where you will need to create a new key pair:

<img src="../img/posts/SparkR/key_pair.png" alt="Key Pair" style='padding:1px; border:1px solid #021a40;'></p>


Key-pair is a security file that will live on your machine and is required to ``SSH`` into the instance. I tend to create them and leave them in my downloads. What ever you decided to do, make sure you know where it is as you’ll need to pass a path to it every time you want to connect to it. Create a new one, check the acknowledgment check-box. 

Finally, click Launch Instances. That’s it for our instance. Hit the View Instances on the next page as the machine is being initialized:

<img src="../img/posts/SparkR/ec2_instance.png" alt="EC2 Instance" style='padding:1px; border:1px solid #021a40;'></p>

We need to wait till the Initializing is done. Meanwhile we can get the security credentials that will be needed to launch the clusters. Go to your account name drop down in the top right corner and click ``Security Credentials``:

<img src="../img/posts/SparkR/ec2_instance.png" alt="Create Instance" style='padding:1px; border:1px solid #021a40;'></p>


